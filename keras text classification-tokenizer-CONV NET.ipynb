{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation\n",
    "from keras.layers.core import Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import json\n",
    "import requests\n",
    "import pickle\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27481 3534\n"
     ]
    }
   ],
   "source": [
    "df_train=pd.read_csv(\"data/train_tweet.csv\",index_col=False)\n",
    "df_test=pd.read_csv(\"data/test_tweet.csv\",index_col=False)\n",
    "print(len(df_train),len(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train=df_train[['textID', 'text', 'sentiment']]\n",
    "df=df_train.append(df_test)\n",
    "len(df)\n",
    "df=df.dropna()\n",
    "df=df[['text', 'sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[\"sentiment\"]=df[\"sentiment\"].astype('category')\n",
    "df[\"sentiment_target\"]=df[\"sentiment\"].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text sentiment  \\\n",
       "0                I`d have responded, if I were going   neutral   \n",
       "1      Sooo SAD I will miss you here in San Diego!!!  negative   \n",
       "2                          my boss is bullying me...  negative   \n",
       "3                     what interview! leave me alone  negative   \n",
       "4   Sons of ****, why couldn`t they put them on t...  negative   \n",
       "\n",
       "   sentiment_target  \n",
       "0                 1  \n",
       "1                 0  \n",
       "2                 0  \n",
       "3                 0  \n",
       "4                 0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31014 31014\n"
     ]
    }
   ],
   "source": [
    "x=df[\"text\"].values\n",
    "y=df[\"sentiment_target\"].values\n",
    "print(len(x),len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentences_train,sentences_test,y_train,y_test=train_test_split(x,y,test_size=0.8,random_state =0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To make a long day short--I did nothing. =D well, I had some friends over they just left (3:55am) We have been drinking since 9.  Smashed\n",
      "[2, 130, 4, 184, 25, 1048, 1, 129, 317, 158, 76, 1, 70, 73, 221, 122, 58, 22, 211, 110, 3947, 53, 18, 98, 718, 262, 511, 1946]\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(sentences_train)\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(sentences_train)\n",
    "X_test = tokenizer.texts_to_sequences(sentences_test)\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1  # Adding 1 because of reserved 0 index\n",
    "\n",
    "print(sentences_train[2])\n",
    "print(X_train[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  51    2  675   73   85 3940 1176 3941    2  532  813    2  109 1349\n",
      "    1  375  128   77   85  406 2571 3942 1177 3943 3944 2572    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0]\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "maxlen = 100\n",
    "\n",
    "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
    "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)\n",
    "\n",
    "print(X_train[0, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 100, 100)          1053700   \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 96, 128)           64128     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 1,119,129\n",
      "Trainable params: 1,119,129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#model\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "\n",
    "embedding_dim = 100\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Embedding(vocab_size, embedding_dim, input_length=maxlen))\n",
    "model.add(layers.Conv1D(128, 5, activation='relu'))\n",
    "model.add(layers.GlobalMaxPooling1D())\n",
    "model.add(layers.Dense(10, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "Train on 6202 samples, validate on 24812 samples\n",
      "Epoch 1/20\n",
      "6202/6202 [==============================] - 20s 3ms/step - loss: -1.5380 - acc: 0.3963 - val_loss: -3.0549 - val_acc: 0.4066\n",
      "Epoch 2/20\n",
      "6202/6202 [==============================] - 19s 3ms/step - loss: -3.5234 - acc: 0.4813 - val_loss: -3.2325 - val_acc: 0.4811\n",
      "Epoch 3/20\n",
      "6202/6202 [==============================] - 19s 3ms/step - loss: -4.0694 - acc: 0.5530 - val_loss: -3.1954 - val_acc: 0.4919\n",
      "Epoch 4/20\n",
      "6202/6202 [==============================] - 19s 3ms/step - loss: -4.3138 - acc: 0.5890 - val_loss: -3.1803 - val_acc: 0.4913\n",
      "Epoch 5/20\n",
      "6202/6202 [==============================] - 21s 3ms/step - loss: -4.4810 - acc: 0.6111 - val_loss: -3.1235 - val_acc: 0.4910\n",
      "Epoch 6/20\n",
      "6202/6202 [==============================] - 21s 3ms/step - loss: -4.5653 - acc: 0.6261 - val_loss: -3.1350 - val_acc: 0.4817\n",
      "Epoch 7/20\n",
      "6202/6202 [==============================] - 18s 3ms/step - loss: -4.6208 - acc: 0.6390 - val_loss: -3.0664 - val_acc: 0.4803\n",
      "Epoch 8/20\n",
      "6202/6202 [==============================] - 18s 3ms/step - loss: -4.6454 - acc: 0.6453 - val_loss: -2.9877 - val_acc: 0.4872\n",
      "Epoch 9/20\n",
      "6202/6202 [==============================] - 18s 3ms/step - loss: -4.6910 - acc: 0.6540 - val_loss: -2.9387 - val_acc: 0.4856\n",
      "Epoch 10/20\n",
      "6202/6202 [==============================] - 18s 3ms/step - loss: -4.7256 - acc: 0.6611 - val_loss: -2.8551 - val_acc: 0.4831\n",
      "Epoch 11/20\n",
      "6202/6202 [==============================] - 18s 3ms/step - loss: -4.7449 - acc: 0.6637 - val_loss: -2.8134 - val_acc: 0.4911\n",
      "Epoch 12/20\n",
      "6202/6202 [==============================] - 18s 3ms/step - loss: -4.7332 - acc: 0.6622 - val_loss: -2.7767 - val_acc: 0.4847\n",
      "Epoch 13/20\n",
      "6202/6202 [==============================] - 18s 3ms/step - loss: -4.7627 - acc: 0.6669 - val_loss: -2.7965 - val_acc: 0.4879\n",
      "Epoch 14/20\n",
      "6202/6202 [==============================] - 18s 3ms/step - loss: -4.7785 - acc: 0.6708 - val_loss: -2.6848 - val_acc: 0.4873\n",
      "Epoch 15/20\n",
      "6202/6202 [==============================] - 18s 3ms/step - loss: -4.7828 - acc: 0.6724 - val_loss: -2.6509 - val_acc: 0.4917\n",
      "Epoch 16/20\n",
      "6202/6202 [==============================] - 18s 3ms/step - loss: -4.8002 - acc: 0.6748 - val_loss: -2.7033 - val_acc: 0.4860\n",
      "Epoch 17/20\n",
      "6202/6202 [==============================] - 18s 3ms/step - loss: -4.7972 - acc: 0.6748 - val_loss: -2.4797 - val_acc: 0.4850\n",
      "Epoch 18/20\n",
      "6202/6202 [==============================] - 18s 3ms/step - loss: -4.8077 - acc: 0.6737 - val_loss: -2.5593 - val_acc: 0.4855\n",
      "Epoch 19/20\n",
      "6202/6202 [==============================] - 18s 3ms/step - loss: -4.8178 - acc: 0.6764 - val_loss: -2.4932 - val_acc: 0.4879\n",
      "Epoch 20/20\n",
      "6202/6202 [==============================] - 18s 3ms/step - loss: -4.8227 - acc: 0.6777 - val_loss: -2.5419 - val_acc: 0.4881\n",
      "Training Accuracy: 0.6785\n",
      "Testing Accuracy:  0.4881\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'plot_history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-0d7ada53a869>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Testing Accuracy:  {:.4f}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mplot_history\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'plot_history' is not defined"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=20,\n",
    "                    verbose=True,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    batch_size=10)\n",
    "loss, accuracy = model.evaluate(X_train, y_train, verbose=False)\n",
    "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
