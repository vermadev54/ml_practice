{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation\n",
    "from keras.layers.core import Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import json\n",
    "import requests\n",
    "import pickle\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27481 3534\n"
     ]
    }
   ],
   "source": [
    "df_train=pd.read_csv(\"data/train_tweet.csv\",index_col=False)\n",
    "df_test=pd.read_csv(\"data/test_tweet.csv\",index_col=False)\n",
    "print(len(df_train),len(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train=df_train[['textID', 'text', 'sentiment']]\n",
    "df=df_train.append(df_test)\n",
    "len(df)\n",
    "df=df.dropna()\n",
    "df=df[['text', 'sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[\"sentiment\"]=df[\"sentiment\"].astype('category')\n",
    "df[\"sentiment_target\"]=df[\"sentiment\"].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text sentiment  \\\n",
       "0                I`d have responded, if I were going   neutral   \n",
       "1      Sooo SAD I will miss you here in San Diego!!!  negative   \n",
       "2                          my boss is bullying me...  negative   \n",
       "3                     what interview! leave me alone  negative   \n",
       "4   Sons of ****, why couldn`t they put them on t...  negative   \n",
       "\n",
       "   sentiment_target  \n",
       "0                 1  \n",
       "1                 0  \n",
       "2                 0  \n",
       "3                 0  \n",
       "4                 0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31014 31014\n"
     ]
    }
   ],
   "source": [
    "x=df[\"text\"].values\n",
    "y=df[\"sentiment_target\"].values\n",
    "print(len(x),len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentences_train,sentences_test,y_train,y_test=train_test_split(x,y,test_size=0.8,random_state =0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To make a long day short--I did nothing. =D well, I had some friends over they just left (3:55am) We have been drinking since 9.  Smashed\n",
      "[2, 130, 4, 184, 25, 1048, 1, 129, 317, 158, 76, 1, 70, 73, 221, 122, 58, 22, 211, 110, 3947, 53, 18, 98, 718, 262, 511, 1946]\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(sentences_train)\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(sentences_train)\n",
    "X_test = tokenizer.texts_to_sequences(sentences_test)\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1  # Adding 1 because of reserved 0 index\n",
    "\n",
    "print(sentences_train[2])\n",
    "print(X_train[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  51    2  675   73   85 3940 1176 3941    2  532  813    2  109 1349\n",
      "    1  375  128   77   85  406 2571 3942 1177 3943 3944 2572    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0]\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "maxlen = 100\n",
    "\n",
    "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
    "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)\n",
    "\n",
    "print(X_train[0, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 100, 50)           526850    \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 5000)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                50010     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 576,871\n",
      "Trainable params: 576,871\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#model\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "embedding_dim = 50\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Embedding(input_dim=vocab_size, \n",
    "                           output_dim=embedding_dim, \n",
    "                           input_length=maxlen))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(10, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6202 samples, validate on 24812 samples\n",
      "Epoch 1/20\n",
      "6202/6202 [==============================] - 8s 1ms/step - loss: -3.0630 - acc: 0.4697 - val_loss: -3.0306 - val_acc: 0.4867\n",
      "Epoch 2/20\n",
      "6202/6202 [==============================] - 8s 1ms/step - loss: -3.8808 - acc: 0.5445 - val_loss: -3.1272 - val_acc: 0.4932\n",
      "Epoch 3/20\n",
      "6202/6202 [==============================] - 8s 1ms/step - loss: -4.2554 - acc: 0.5784 - val_loss: -3.1282 - val_acc: 0.4929\n",
      "Epoch 4/20\n",
      "6202/6202 [==============================] - 8s 1ms/step - loss: -4.4628 - acc: 0.6048 - val_loss: -3.1083 - val_acc: 0.4904\n",
      "Epoch 5/20\n",
      "6202/6202 [==============================] - 8s 1ms/step - loss: -4.6028 - acc: 0.6251 - val_loss: -3.0368 - val_acc: 0.4919\n",
      "Epoch 6/20\n",
      "6202/6202 [==============================] - 8s 1ms/step - loss: -4.7020 - acc: 0.6477 - val_loss: -3.0343 - val_acc: 0.4937\n",
      "Epoch 7/20\n",
      "6202/6202 [==============================] - 9s 1ms/step - loss: -4.7609 - acc: 0.6617 - val_loss: -2.9646 - val_acc: 0.4917\n",
      "Epoch 8/20\n",
      "6202/6202 [==============================] - 10s 2ms/step - loss: -4.8036 - acc: 0.6696 - val_loss: -2.8901 - val_acc: 0.4925\n",
      "Epoch 9/20\n",
      "6202/6202 [==============================] - 7s 1ms/step - loss: -4.8256 - acc: 0.6727 - val_loss: -2.8676 - val_acc: 0.4904\n",
      "Epoch 10/20\n",
      "6202/6202 [==============================] - 8s 1ms/step - loss: -4.8388 - acc: 0.6762 - val_loss: -2.7982 - val_acc: 0.4884\n",
      "Epoch 11/20\n",
      "6202/6202 [==============================] - 8s 1ms/step - loss: -4.8512 - acc: 0.6780 - val_loss: -2.7105 - val_acc: 0.4867\n",
      "Epoch 12/20\n",
      "6202/6202 [==============================] - 8s 1ms/step - loss: -4.8593 - acc: 0.6798 - val_loss: -2.6478 - val_acc: 0.4876\n",
      "Epoch 13/20\n",
      "6202/6202 [==============================] - 8s 1ms/step - loss: -4.8639 - acc: 0.6796 - val_loss: -2.6563 - val_acc: 0.4855\n",
      "Epoch 14/20\n",
      "6202/6202 [==============================] - 8s 1ms/step - loss: -4.8716 - acc: 0.6798 - val_loss: -2.6144 - val_acc: 0.4855\n",
      "Epoch 15/20\n",
      "6202/6202 [==============================] - 7s 1ms/step - loss: -4.8771 - acc: 0.6817 - val_loss: -2.5056 - val_acc: 0.4846\n",
      "Epoch 16/20\n",
      "6202/6202 [==============================] - 8s 1ms/step - loss: -4.8751 - acc: 0.6803 - val_loss: -2.5186 - val_acc: 0.4822\n",
      "Epoch 17/20\n",
      "6202/6202 [==============================] - 8s 1ms/step - loss: -4.8802 - acc: 0.6819 - val_loss: -2.4377 - val_acc: 0.4866\n",
      "Epoch 18/20\n",
      "6202/6202 [==============================] - 8s 1ms/step - loss: -4.8829 - acc: 0.6822 - val_loss: -2.2894 - val_acc: 0.4872\n",
      "Epoch 19/20\n",
      "6202/6202 [==============================] - 9s 1ms/step - loss: -4.8848 - acc: 0.6817 - val_loss: -2.4608 - val_acc: 0.4816\n",
      "Epoch 20/20\n",
      "6202/6202 [==============================] - 8s 1ms/step - loss: -4.8879 - acc: 0.6830 - val_loss: -2.4231 - val_acc: 0.4813\n",
      "Training Accuracy: 0.6825\n",
      "Testing Accuracy:  0.4813\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'plot_history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-0d7ada53a869>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Testing Accuracy:  {:.4f}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mplot_history\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'plot_history' is not defined"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=20,\n",
    "                    verbose=True,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    batch_size=10)\n",
    "loss, accuracy = model.evaluate(X_train, y_train, verbose=False)\n",
    "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
